{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanyaclement/IntroDH/blob/master/social_network/Social_Network_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "O8PiYDx4q6Hc"
      },
      "source": [
        "# Wk 13 Workshop: Social Network Analysis\n",
        "\n",
        "\n",
        "Taken from [https://medium.com/@finalfire](https://medium.com/@finalfire)\n",
        "\n",
        "Tutorial has been modified using Walsh's Introduction to Cultutral Analytics Section on Network Analysis [https://melaniewalsh.github.io/Intro-Cultural-Analytics/06-Network-Analysis/00-Network-Analysis.html]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this workshop you will use an assigned data set found [here](https://drive.google.com/drive/folders/1qPhEH3d-_4C8_47A-xFA49YuV_dx9aOG?usp=share_link)\n",
        "\n",
        "Each group will be assigned a novel at random üòâ your task will be to guess what novel you are analyzing."
      ],
      "metadata": {
        "id": "KPmDEV823k4N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Set up of data üîÄ"
      ],
      "metadata": {
        "id": "UVsiUefL2P2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load the data into your colab please follow these steps:\n",
        "\n",
        "\n",
        "1.   Download group `Characters_list.txt` and `text.txt`\n",
        "2.   Click on the folder icon üìÅ on the left pane.\n",
        "3.   Once the right pane opens click the upload icon that has a page with an arrow pointing up.\n",
        "4.  You may upload both `Characters_list.txt` and `text.txt`. wait for the orange circles to disappear so you can use the data with out any issues.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oV3mxRdZ4OpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets start sorting our character database!\n",
        "! pip install tinydb"
      ],
      "metadata": {
        "id": "8ZlDj2O3rGRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ccRIchVEq6Hd"
      },
      "outputs": [],
      "source": [
        "from tinydb import TinyDB, Query\n",
        "\n",
        "db = TinyDB('characters.json')\n",
        "\n",
        "# read all of the characters from the list\n",
        "# the list has been created by POS-tagging all of the file 'text'\n",
        "# using nltk\n",
        "with open('characters_list.txt') as in_file: #Check the name of your file and make sure it matches ;)\n",
        "    chars = [row.strip() for row in in_file]\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "lS8Wsh9pq6He"
      },
      "outputs": [],
      "source": [
        "#matplotlib inline\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "\n",
        "def build_regexp(c):\n",
        "    \"\"\"\n",
        "    Creates the appropriate regex for the expressions\n",
        "    N(M) or N,M\n",
        "    \"\"\"\n",
        "    if '(' in c:\n",
        "        a, b = c.split(' ')\n",
        "        b = b[1:-1]\n",
        "        r = r\"{}( {})?\".format(a, b)\n",
        "        return r\n",
        "    if ',' in c:\n",
        "        a, b = c.split(',')\n",
        "        r = r\"({}|{})\".format(a, b)\n",
        "        return r\n",
        "    return r\"{}\".format(c)\n",
        "\n",
        "\n",
        "## save everything\n",
        "with open('G2_characters_list.txt') as x: #if there is an error pointing to this line make sure to check the name of the file matching the code ;)\n",
        "    characters = [l.strip() for l in x]\n",
        "\n",
        "with open('G2_text.txt') as x: #if there is an error pointing to this line make sure to check the name of the file matching the code ;)\n",
        "    text = [l.strip() for l in x]\n",
        "raw = ' '.join(text)\n",
        "\n",
        "## map the characters\n",
        "chars = {}\n",
        "\n",
        "for it, c in enumerate(characters):\n",
        "    chars[it] = c\n",
        "    template = '{}'.format(it)\n",
        "    regexp = re.compile(build_regexp(c))\n",
        "    raw = re.sub(regexp, template, raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ZcYYRXrEq6He"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "nltk.download('punkt')\n",
        "\n",
        "print('Total characters:', len(characters))\n",
        "\n",
        "# build the graph\n",
        "g = nx.Graph()\n",
        "# add nodes\n",
        "for c in characters:\n",
        "    g.add_node(c)\n",
        "\n",
        "# tokenize the text\n",
        "words = [n for n in nltk.word_tokenize(raw) if n != ',' and n != '.']\n",
        "\n",
        "# utils list\n",
        "characters_rep = [str(i) for i in range(len(characters))]\n",
        "\n",
        "# forward threshold\n",
        "fwd_t = 30\n",
        "# check for each character\n",
        "for it, c in enumerate(characters):\n",
        "    for i, word in enumerate(words):\n",
        "        if word == str(it):\n",
        "            for d in range(i, i + fwd_t + 1):\n",
        "                if d < len(words):\n",
        "                    if words[d] in characters_rep and words[d] != word:\n",
        "                        src_node = chars[int(word)]\n",
        "                        target_node = chars[int(words[d])]\n",
        "                        if target_node not in g[src_node]:\n",
        "                            g.add_edge(src_node, target_node, weight=1)\n",
        "                        else:\n",
        "                            g[src_node][target_node]['weight'] += 1\n",
        "\n",
        "# remove nodes w/o edges\n",
        "removed = set()\n",
        "for node in list(g.nodes()):\n",
        "    if not g[node]:\n",
        "        print('Node w/o edges:', node)\n",
        "        g.remove_node(node)\n",
        "        removed.add(node)\n",
        "\n",
        "print('Total characters minus solitude nodes:', len(g.nodes()))\n",
        "\n",
        "nx.write_graphml(g, 'output.graphml')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "gT0_ywFDq6Hf"
      },
      "outputs": [],
      "source": [
        "# If you run this and you get no error, then all characters in your list are interconnected.\n",
        "# If you get an error, that means there may be some characters are not connected to the main network. DO not worry, just continue to the next step\n",
        "print('Diameter:', nx.diameter(g))\n",
        "print('Degree centrality:', nx.degree_centrality(g))\n",
        "print('Betweennes centrality:', nx.betweenness_centrality(g))\n",
        "print('Closeness centrality:', nx.closeness_centrality(g))\n",
        "print('Pagerank:', nx.pagerank(g))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let see our initial network graph\n",
        "nx.draw(g)\n",
        "\n"
      ],
      "metadata": {
        "id": "Zu4zJovR44wI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets ponder...\n",
        "The code did everything we asked it to, and we got a graph. So why is it soo ugly and confusing?\n",
        "What could we do better?"
      ],
      "metadata": {
        "id": "JN5D3f_lLzKu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer here:"
      ],
      "metadata": {
        "id": "LJXq8ignL-oC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Well that was ugly... lets try this instead...\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "nx.draw(g, with_labels=True, node_color='skyblue', width=.3, font_size=8)"
      ],
      "metadata": {
        "id": "Bhrgmo8m6dvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Data Inspection and Manipulation üìÖ"
      ],
      "metadata": {
        "id": "5lUyDnM83LsQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this portion we will inspect our data and try to decipher what novel you were assigned. We will do this by exploring:\n",
        "*  Who has the most connections? (*Degree* & *weighted degree*).\n",
        "*  Who connects the most other nodes in the network (*Betweeness*).\n",
        "*  Create groupings based on the algorithms (*Community*).\n",
        "\n",
        "NetworkX has very powerful algorithmic tools that allows us to see the different relationships that arise in the novel and aids us in making predictions."
      ],
      "metadata": {
        "id": "WVSpjJhOESG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "HLPkSF4sGry-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Degree: Who has the most connections?\n",
        "#algorithm\n",
        "nx.degree(g)\n",
        "#create dictionary\n",
        "degrees = dict(nx.degree(g))\n",
        "nx.set_node_attributes(g, name='degree', values=degrees)\n",
        "#dataframe it <3\n",
        "degree_df = pd.DataFrame(g.nodes(data='degree'), columns=['node', 'degree'])\n",
        "degree_df = degree_df.sort_values(by='degree', ascending=False)\n",
        "degree_df\n",
        "#graph\n",
        "num_nodes_to_inspect = 10\n",
        "degree_df[:num_nodes_to_inspect].plot(x='node', y='degree', kind='barh').invert_yaxis()"
      ],
      "metadata": {
        "id": "3bmWaV9vEQQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Lets stop and think...\n",
        "1.   What are the top 10 characters listed?\n",
        "2.   What literary work does it remind you of?\n",
        "\n"
      ],
      "metadata": {
        "id": "CeYtOC8qGDHa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Type answer here:"
      ],
      "metadata": {
        "id": "LZSGqe7PGA14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Degree Weighted: Paying attention to edges, who has the most connections?\n",
        "#recalibrate the algorithm\n",
        "nx.degree(g, weight='Weight')\n",
        "#Dictionary creation\n",
        "weighted_degrees = dict(nx.degree(g, weight='Weight'))\n",
        "nx.set_node_attributes(g, name='weighted_degree', values=weighted_degrees)\n",
        "#Data Fram\n",
        "weighted_degree_df = pd.DataFrame(g.nodes(data='weighted_degree'), columns=['node', 'weighted_degree'])\n",
        "weighted_degree_df = weighted_degree_df.sort_values(by='weighted_degree', ascending=False)\n",
        "weighted_degree_df\n",
        "#graph\n",
        "num_nodes_to_inspect = 10\n",
        "weighted_degree_df[:num_nodes_to_inspect].plot(x='node', y='weighted_degree', color='orange', kind='barh').invert_yaxis()"
      ],
      "metadata": {
        "id": "rEwQl3AYGAZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Ok now lets compare and contrast:\n",
        "1.   Do you see any differences between plot 1 and plot 2?\n",
        "2.   Has your prediction changed? Why?\n",
        "\n"
      ],
      "metadata": {
        "id": "XhcptW9pGzzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer:"
      ],
      "metadata": {
        "id": "pORNkkCuG-6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Betweeness: lets now look who creates the most connections\n",
        "#Algorithm\n",
        "nx.betweenness_centrality(g)\n",
        "# running more algorithms\n",
        "betweenness_centrality = nx.betweenness_centrality(g)\n",
        "nx.set_node_attributes(g, name='betweenness', values=betweenness_centrality)\n",
        "#Dataframing\n",
        "betweenness_df = pd.DataFrame(g.nodes(data='betweenness'), columns=['node', 'betweenness'])\n",
        "betweenness_df = betweenness_df.sort_values(by='betweenness', ascending=False)\n",
        "betweenness_df\n",
        "#graph\n",
        "num_nodes_to_inspect = 10\n",
        "betweenness_df[:num_nodes_to_inspect].plot(x='node', y='betweenness', color='green', kind='barh').invert_yaxis()"
      ],
      "metadata": {
        "id": "_i0zCI7zVhqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets pause and answer:\n",
        "\n",
        "\n",
        "*   Which character has the most connections?\n",
        "*   Why do you believe this happens?\n",
        "*   Has your prediction changed? Why?\n",
        "\n"
      ],
      "metadata": {
        "id": "56yFkl38Hfks"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer goes here:"
      ],
      "metadata": {
        "id": "79uhEOncHuB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets build groups of characters!!!\n",
        "from networkx.algorithms import community"
      ],
      "metadata": {
        "id": "FFnxadNaWP63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#recall function\n",
        "communities = community.greedy_modularity_communities(g)\n",
        "communities\n",
        "# Create empty dictionary\n",
        "modularity_class = {}\n",
        "#Loop through each community in the network\n",
        "for community_number, community in enumerate(communities):\n",
        "    #For each member of the community, add their community number\n",
        "    for name in community:\n",
        "        modularity_class[name] = community_number\n",
        "nx.set_node_attributes(g, modularity_class, 'modularity_class')\n",
        "#dataframe\n",
        "communities_df = pd.DataFrame(g.nodes(data='modularity_class'), columns=['node', 'modularity_class'])\n",
        "communities_df = communities_df.sort_values(by='modularity_class', ascending=False)\n",
        "communities_df\n"
      ],
      "metadata": {
        "id": "eILH39ccWUk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets visualize it :)\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "mF8JkuQyWfN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Set figure size\n",
        "plt.figure(figsize=(4,12))\n",
        "\n",
        "#Plot a categorical scatter plot from the dataframe communities_df.sample(40)\n",
        "ax =sns.stripplot(x='modularity_class', y='node', data=communities_df.sample(20),\n",
        "              hue='modularity_class', marker='*',size=15)\n",
        "#Set legend outside the plot with bbox_to_anchor\n",
        "ax.legend(loc='upper right',bbox_to_anchor=(1.5, 1), title='Modularity Class')\n",
        "ax.set_title(\"Characters By Modularity Class\\n(Random Sample)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9LpHIREyXN6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets try to see everyone now\n",
        "plt.figure(figsize=(4,25))\n",
        "\n",
        "ax =sns.stripplot(x='modularity_class', y='node', data=communities_df,\n",
        "              hue='modularity_class', marker='*',size=15)\n",
        "\n",
        "ax.legend(loc='upper right',bbox_to_anchor=(1.5, 1), title='Modularity Class')\n",
        "ax.set_title(\"EASTER EGG XD Characters By Modularity Class\") #Change the title of your graph to reflect the book you think YOU are analyzing ;)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0O-ka9mOXSoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, there's been a lot going on... lets reflect again:\n",
        "\n",
        "\n",
        "1.   How many communities did your text have?\n",
        "2.   Do the results align with your initial prediction?\n",
        "\n"
      ],
      "metadata": {
        "id": "vjO6wvYeIgg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets put all of our algorithmic functions into one table\n",
        "dict(g.nodes(data=True))\n",
        "nodes_df = pd.DataFrame(dict(g.nodes(data=True))).T\n",
        "nodes_df"
      ],
      "metadata": {
        "id": "T-rsh6kAXaqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# if you wish to rearrange...\n",
        "nodes_df.sort_values(by='betweenness', ascending=False)"
      ],
      "metadata": {
        "id": "sKTSWYlcX1q6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Better 'Interactive' visualizations üò∏"
      ],
      "metadata": {
        "id": "IEQ7-_Sj7h5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.io import output_notebook, show, save"
      ],
      "metadata": {
        "id": "GbKxW67h7lfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_notebook()"
      ],
      "metadata": {
        "id": "O2wgYdzd7tAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bokeh.io import output_notebook, show, save\n",
        "from bokeh.models import Range1d, Circle, ColumnDataSource, MultiLine\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.plotting import from_networkx\n",
        "from bokeh.palettes import Blues8, Reds8, Purples8, Oranges8, Viridis8, Spectral8\n",
        "from bokeh.transform import linear_cmap\n",
        "from networkx.algorithms import community"
      ],
      "metadata": {
        "id": "2KLvwzsu7woc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "degrees = dict(nx.degree(g))\n",
        "nx.set_node_attributes(g, name='degree', values=degrees)"
      ],
      "metadata": {
        "id": "L9E9XuuU78t6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "number_to_adjust_by = 5\n",
        "adjusted_node_size = dict([(node, degree+number_to_adjust_by) for node, degree in nx.degree(g)])\n",
        "nx.set_node_attributes(g, name='adjusted_node_size', values=adjusted_node_size)"
      ],
      "metadata": {
        "id": "mmyV1Aig8MnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "communities = community.greedy_modularity_communities(g)"
      ],
      "metadata": {
        "id": "BPV6VF_N8SqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create empty dictionaries\n",
        "modularity_class = {}\n",
        "modularity_color = {}\n",
        "#Loop through each community in the network\n",
        "for community_number, community in enumerate(communities):\n",
        "    #For each member of the community, add their community number and a distinct color\n",
        "    for name in community:\n",
        "        modularity_class[name] = community_number\n",
        "        modularity_color[name] = Spectral8[community_number]"
      ],
      "metadata": {
        "id": "Zwv16xtV8Wq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add modularity class and color as attributes from the network above\n",
        "nx.set_node_attributes(g, modularity_class, 'modularity_class')\n",
        "nx.set_node_attributes(g, modularity_color, 'modularity_color')"
      ],
      "metadata": {
        "id": "QdNE5S528Z9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choose attributes from G network to size and color by ‚Äî setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
        "size_by_this_attribute = 'adjusted_node_size'\n",
        "color_by_this_attribute = 'modularity_color'\n",
        "#Pick a color palette ‚Äî Blues8, Reds8, Purples8, Oranges8, Viridis8\n",
        "color_palette = Blues8\n",
        "#Choose a title!\n",
        "title = 'Lord of the Rings<' #Set the Name to the novel you think you are analyzing!\n",
        "\n",
        "#Establish which categories will appear when hovering over each node\n",
        "HOVER_TOOLTIPS = [\n",
        "       (\"Character\", \"@index\"),\n",
        "        (\"Degree\", \"@degree\"),\n",
        "         (\"Modularity Class\", \"@modularity_class\"),\n",
        "        (\"Modularity Color\", \"$color[swatch]:modularity_color\"),\n",
        "]\n",
        "\n",
        "#Create a plot ‚Äî set dimensions, toolbar, and title\n",
        "plot = figure(tooltips = HOVER_TOOLTIPS,\n",
        "              tools=\"pan,wheel_zoom,save,reset, tap\", active_scroll='wheel_zoom',\n",
        "            x_range=Range1d(-10.1, 10.1), y_range=Range1d(-10.1, 10.1), title=title)\n",
        "\n",
        "#Create a network graph object\n",
        "# https://networkx.github.io/documentation/networkx-1.9/reference/generated/networkx.drawing.layout.spring_layout.html\n",
        "network_graph = from_networkx(g, nx.spring_layout, scale=10, center=(0, 0))\n",
        "\n",
        "#Set node sizes and colors according to node degree (color as category from attribute)\n",
        "network_graph.node_renderer.glyph = Circle(size=size_by_this_attribute, fill_color=color_by_this_attribute)\n",
        "\n",
        "#Set edge opacity and width\n",
        "network_graph.edge_renderer.glyph = MultiLine(line_alpha=0.5, line_width=1)\n",
        "\n",
        "plot.renderers.append(network_graph)\n",
        "\n",
        "show(plot)\n",
        "#save(plot, filename=f\"{title}.html\")"
      ],
      "metadata": {
        "id": "wcVRRzNF8gEP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The moment of Truth...\n",
        "\n",
        "\n",
        "1.   What novel did you just analyze?\n",
        "2.   Which step helped you figure it out? Why?\n",
        "\n"
      ],
      "metadata": {
        "id": "eBS0GlRjK7ZM"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}